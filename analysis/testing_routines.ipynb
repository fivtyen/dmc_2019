{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bunch of functions to automate ML models testing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_data(df, minority_var, n):\n",
    "    \"\"\"\n",
    "    Input: df:pandas.DataFrame, minority_var:str, n:int.\n",
    "    Output: df_upsampled:pandas.DataFrame.\n",
    "    \n",
    "    Returns dataset with equal number of observations in each class.\n",
    "    Samples from minority class are multiplied.\n",
    "    \"\"\"\n",
    "    df_minority = df[df[minority_var] == 1]\n",
    "    df_majority = df[df[minority_var] == 0]\n",
    "    df_minority_up = resample(df_minority, replace=True, n_samples=n)\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_up])\n",
    "    return df_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_data(df, minority_var, n):\n",
    "    \"\"\"\n",
    "    Input: df:pandas.DataFrame, minority_var:str, n:int.\n",
    "    Output: df_upsampled:pandas.DataFrame.\n",
    "    \n",
    "    Returns dataset with equal number of observations in each class.\n",
    "    Samples from majority class are selected to match the number of \n",
    "    samples in the minority class.\n",
    "    \"\"\"\n",
    "    df_minority = df[df[minority_var] == 1]\n",
    "    df_majority = df[df[minority_var] == 0]\n",
    "    df_majority_down = resample(df_majority, replace=False, n_samples=n)\n",
    "    df_downsampled = pd.concat([df_minority, df_majority_down])\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataframe into format suitable for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_frame(df, dep_var):\n",
    "    \"\"\"\n",
    "    Input: df:pandas.DataFrame, dep_var:str.\n",
    "    Output: X:padas.DataFrame, y:pandas.Series.\n",
    "    \n",
    "    Splits data into dataframe with independent variables\n",
    "    and data series with the dependent variable.\n",
    "    \"\"\"\n",
    "    X = df.drop(dep_var, axis=1)\n",
    "    y = df[dep_var]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model testing routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model_flow(model, X, y, test_size=0.25, visualisations=False):\n",
    "    \"\"\"\n",
    "    Input: model:sklearn model, X:pandas.DataFame, y:padas.Series, test_size:float, visualisations:Boolean.\n",
    "    Output: None.\n",
    "    \n",
    "    For given model and data performes the training and returns multiple testing measures.\n",
    "    If visualisations == True, produces plots to visualise certain measures.\n",
    "    \"\"\"                   \n",
    "                       \n",
    "    name = type(model).__name__\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    model.fit(X, y)\n",
    "    accuracy = round(model.score(X_test, y_test), 3)\n",
    "\n",
    "    prob_y_vis = model.predict_proba(X_test)\n",
    "    prob_y = [p[1] for p in prob_y_vis]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    roc_auc = round(roc_auc_score(y_test, prob_y), 3)\n",
    "    precision = round(precision_score(y_test, y_pred), 3)\n",
    "    recall = round(recall_score(y_test, y_pred), 3)\n",
    "    f1 = round(f1_score(y_test, y_pred), 3)\n",
    "    \n",
    "    if visualisations:\n",
    "        skplt.metrics.plot_roc(y_test, prob_y_vis)\n",
    "        plt.title('{} ROC Curves'.format(name))\n",
    "        plt.show()\n",
    "        \n",
    "        skplt.metrics.plot_precision_recall(y_test, prob_y_vis)\n",
    "        plt.title('{} Precision-Recall Curve'.format(name))\n",
    "        plt.show()\n",
    "\n",
    "    print('{} - precision: {}, recall: {}, F1: {}, ROC: {}'.format(name, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cross_calidation_flow(model, X, y, cv=5):\n",
    "    name = type(model).__name__\n",
    "    measures = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    print(name)\n",
    "    for measure in measures:\n",
    "        res = cross_val_score(model, X, y, cv=cv, scoring=measure)\n",
    "        print(measure, *res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "accuracy 0.9929577464788732 0.9887323943661972 0.9915492957746479 0.995774647887324 0.9971830985915493\n",
      "precision 0.9943977591036415 0.9806629834254144 0.9806629834254144 0.9943977591036415 0.9916201117318436\n",
      "recall 1.0 1.0 1.0 1.0 1.0\n",
      "f1 0.9957924263674615 0.9861111111111112 0.9847434119278778 0.993006993006993 0.9957924263674615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../data/train.csv', '|')\n",
    "dfu = upsample_data(df, 'fraud', 1775)\n",
    "X, y = split_data_frame(dfu, 'fraud')\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "execute_cross_calidation_flow(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "accuracy 0.9523809523809523 0.9761904761904762 0.9761904761904762 0.9047619047619048 0.95\n",
      "precision 0.95 1.0 0.9090909090909091 0.875 0.9444444444444444\n",
      "recall 0.9047619047619048 0.9523809523809523 0.9047619047619048 0.9523809523809523 0.95\n",
      "f1 0.9500000000000001 0.9767441860465117 0.9767441860465117 0.9333333333333333 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv', '|')\n",
    "dfu = downsample_data(df, 'fraud', 104)\n",
    "X, y = split_data_frame(dfu, 'fraud')\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "execute_cross_calidation_flow(clf, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
