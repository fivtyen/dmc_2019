{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling and downsampling with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1775\n",
       "1     104\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv', '|')\n",
    "df.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb = df.drop('fraud', axis=1)\n",
    "y_imb = df['fraud']\n",
    "\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb =  train_test_split(X_imb, y_imb, test_size=0.2)\n",
    "\n",
    "clf_imb = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=123) \n",
    "clf_imb.fit(X_train_imb, y_train_imb)\n",
    "clf_imb.score(X_test_imb, y_test_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_imb = clf_imb.predict_proba(X_test_imb)\n",
    "prob_y_imb = [p[1] for p in prob_y_imb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_imb, prob_y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_y_imb_vis = clf_imb.predict_proba(X_test_imb)\n",
    "skplt.metrics.plot_roc(y_test_imb, prob_y_imb_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imb_pred = clf_imb.predict(X_test_imb)\n",
    "precision_imb = precision_score(y_test_imb, y_imb_pred)\n",
    "recall_imb = recall_score(y_test_imb, y_imb_pred)\n",
    "f1_imb = f1_score(y_test_imb, y_imb_pred)\n",
    "print('Precision: {}, recall: {}, F1: {}'.format(precision_imb, recall_imb, f1_imb))\n",
    "\n",
    "skplt.metrics.plot_precision_recall(y_test_imb, prob_y_imb_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraudlent_imbalanced = df[df['fraud'] == 1]\n",
    "df_non_fraudlent_imbalanced = df[df['fraud'] == 0]\n",
    "df_non_fraudlent_downsampled = resample(df_non_fraudlent_imbalanced, \n",
    "                                        replace=False, \n",
    "                                        n_samples=104, \n",
    "                                        random_state=123)\n",
    "df_downsampled = pd.concat([df_fraudlent_imbalanced, df_non_fraudlent_downsampled])\n",
    "df_downsampled.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_down = df_downsampled.drop('fraud', axis=1)\n",
    "y_down = df_downsampled['fraud']\n",
    "\n",
    "X_train_down, X_test_down, y_train_down, y_test_down = train_test_split(X_down, y_down, test_size=0.2)\n",
    "\n",
    "clf_down = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=123) \n",
    "clf_down.fit(X_train_down, y_train_down)\n",
    "clf_down.score(X_test_down, y_test_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_down = clf_down.predict_proba(X_test_down)\n",
    "prob_y_down = [p[1] for p in prob_y_down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_down, prob_y_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_y_down_vis = clf_down.predict_proba(X_test_down)\n",
    "skplt.metrics.plot_roc(y_test_down, prob_y_down_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_down_pred = clf_down.predict(X_test_down)\n",
    "precision_down = precision_score(y_test_down, y_down_pred)\n",
    "recall_down = recall_score(y_test_down, y_down_pred)\n",
    "f1_down = f1_score(y_test_down, y_down_pred)\n",
    "print('Precision: {}, recall: {}, F1: {}'.format(precision_down, recall_down, f1_down))\n",
    "\n",
    "skplt.metrics.plot_precision_recall(y_test_down, prob_y_down_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraudlent_imbalanced = df[df['fraud'] == 1]\n",
    "df_non_fraudlent_imbalanced = df[df['fraud'] == 0]\n",
    "df_fraudlent_up = resample(df_fraudlent_imbalanced, \n",
    "                           replace=True, \n",
    "                           n_samples=1775, \n",
    "                           random_state=123)\n",
    "df_upsampled = pd.concat([df_non_fraudlent_imbalanced, df_fraudlent_up])\n",
    "df_upsampled.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up = df_upsampled.drop('fraud', axis=1)\n",
    "y_up = df_upsampled['fraud']\n",
    "\n",
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_up, y_up, test_size=0.2)\n",
    "\n",
    "clf_up = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=123) \n",
    "clf_up.fit(X_train_up, y_train_up)\n",
    "clf_up.score(X_test_up, y_test_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_up = clf_up.predict_proba(X_test_up)\n",
    "prob_y_up = [p[1] for p in prob_y_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_up, prob_y_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prob_y_up_vis = clf_up.predict_proba(X_test_up)\n",
    "skplt.metrics.plot_roc(y_test_up, prob_y_up_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_up_pred = clf_up.predict(X_test_up)\n",
    "precision_up = precision_score(y_test_up, y_up_pred)\n",
    "recall_up = recall_score(y_test_up, y_up_pred)\n",
    "f1_up = f1_score(y_test_up, y_up_pred)\n",
    "print('Precision: {}, recall: {}, F1: {}'.format(precision_up, recall_up, f1_up))\n",
    "\n",
    "skplt.metrics.plot_precision_recall(y_test_up, prob_y_up_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test whether feature normalization can improve precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm, y_norm = X_up, y_up\n",
    "X_norm = normalize(X_norm)\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y_norm, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_norm = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=123) \n",
    "clf_norm.fit(X_train_norm, y_train_norm)\n",
    "clf_norm.score(X_test_norm, y_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_norm = clf_norm.predict_proba(X_test_norm)\n",
    "prob_y_norm = [p[1] for p in prob_y_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_norm, prob_y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_norm_vis = clf_norm.predict_proba(X_test_norm)\n",
    "skplt.metrics.plot_roc(y_test_norm, prob_y_norm_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_norm_pred = clf_norm.predict(X_test_norm)\n",
    "precision_norm = precision_score(y_test_norm, y_norm_pred)\n",
    "recall_norm = recall_score(y_test_norm, y_norm_pred)\n",
    "f1_norm = f1_score(y_test_norm, y_norm_pred)\n",
    "print('Precision: {}, recall: {}, F1: {}'.format(precision_norm, recall_norm, f1_norm))\n",
    "\n",
    "skplt.metrics.plot_precision_recall(y_test_norm, prob_y_norm_vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no visible improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
